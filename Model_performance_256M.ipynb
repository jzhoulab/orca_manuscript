{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if os.getenv(\"ORCA_PATH\"):\n",
    "    ORCA_PATH = os.getenv(\"ORCA_PATH\")\n",
    "else:\n",
    "    # change this to the right path if you use a different path\n",
    "    # or specify the ORCA_PATH environmental variable\n",
    "    ORCA_PATH = \"../orca\"\n",
    "sys.path.append(ORCA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In <PYTHONPATH>/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.frameon rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In <PYTHONPATH>/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.level rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n",
      "In <PYTHONPATH>/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The verbose.fileo rcparam was deprecated in Matplotlib 3.1 and will be removed in 3.3.\n"
     ]
    }
   ],
   "source": [
    "import orca_predict\n",
    "orca_predict.load_resources(models=['256M'],use_cuda=True)\n",
    "from orca_predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selene_utils2 import *\n",
    "sampler_h1esc = RandomPositionsSamplerHiC(\n",
    "                 reference_sequence = MemmapGenome(ORCA_PATH+'/resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa', memmapfile='./resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa.mmap'),\n",
    "                 target= Genomic2DFeatures([ORCA_PATH+'/resources/4DNFI9GMP2J8.rebinned.mcool::/resolutions/32000'],\n",
    "                           ['r8000'],\n",
    "                          (8000,8000),\n",
    "                          cg=True),\n",
    "                 features = ['r4000'],\n",
    "                 test_holdout=['chr8', 'chr9'],\n",
    "                 validation_holdout= ['chr10'],\n",
    "                 sequence_length= 256000000,\n",
    "                 position_resolution=32000,\n",
    "                 random_shift=0,\n",
    "                 random_strand=False,\n",
    "                 cross_chromosome=True,\n",
    "                 permute_segments=False,\n",
    "                 background_cis_file=ORCA_PATH+'/resources/4DNFI9GMP2J8.rebinned.mcool.expected.res32000.mono.npy',\n",
    "                 background_trans_file=ORCA_PATH+'/resources/4DNFI9GMP2J8.rebinned.mcool.expected.res32000.trans.npy'\n",
    " )\n",
    "    \n",
    "sampler_hff = RandomPositionsSamplerHiC(\n",
    "                 reference_sequence = MemmapGenome(ORCA_PATH+'/resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa', memmapfile='./resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa.mmap'),\n",
    "                 target= Genomic2DFeatures([ORCA_PATH+'/resources/4DNFI643OYP9.rebinned.mcool::/resolutions/32000'],\n",
    "                           ['r8000'],\n",
    "                          (8000,8000),\n",
    "                          cg=True),\n",
    "                 features = ['r4000'],\n",
    "                 test_holdout=['chr8', 'chr9'],\n",
    "                 validation_holdout= ['chr10'],\n",
    "                 sequence_length= 256000000,\n",
    "                 position_resolution=32000,\n",
    "                 random_shift=0,\n",
    "                 random_strand=False,\n",
    "                 cross_chromosome=True,\n",
    "                 permute_segments=False,\n",
    "                 background_cis_file=ORCA_PATH+'/resources/4DNFI643OYP9.rebinned.mcool.expected.res32000.mono.npy',\n",
    "                 background_trans_file=ORCA_PATH+'/resources/4DNFI643OYP9.rebinned.mcool.expected.res32000.trans.npy'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<PYTHONPATH>/lib/python3.7/site-packages/cooltools/lib/numutils.py:1317: RuntimeWarning: invalid value encountered in true_divide\n",
      "  val_cur = ar_cur / armask_cur\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/cooltools/lib/numutils.py:1317: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  val_cur = ar_cur / armask_cur\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:43: RuntimeWarning: Mean of empty slice\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "#32-256Mb model evaluation, intrachromosomal interactions\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "    \n",
    "    mallpreds = []\n",
    "    malltargets = []\n",
    "    malltargetnans = []\n",
    "\n",
    "    for chrm in ['chr9','chr10']:\n",
    "        chrlen = [len for c, len in hg38.get_chr_lens() if c == chrm][0]\n",
    "        chrlen_round = chrlen - chrlen % 32000\n",
    "        \n",
    "        sequences, targets_h1esc, normmats_h1esc = sampler_h1esc._retrieve_multi(*list(zip([chrm, 0, chrlen_round],['chr1',0, 256000000-chrlen_round])))\n",
    "        _, targets_hff, normmats_hff = sampler_hff._retrieve_multi(*list(zip([chrm, 0, chrlen_round],['chr1',0, 256000000-chrlen_round])))\n",
    "\n",
    "        sequences = np.vstack(sequences)\n",
    "        targets_h1esc = np.vstack([np.hstack(l) for l in targets_h1esc])\n",
    "        normmats_h1esc = np.vstack([np.hstack(l) for l in normmats_h1esc])\n",
    "        targets_hff = np.vstack([np.hstack(l) for l in targets_hff])\n",
    "        normmats_hff = np.vstack([np.hstack(l) for l in normmats_hff])\n",
    "        \n",
    "        binstarts = []\n",
    "        for level in [32, 64, 128, 256]:\n",
    "             binstarts.append(np.arange(0, (chrlen_round - level * 1000000) / 32000 , 5120000/32000))\n",
    "\n",
    "        for binstart in binstarts[0]:\n",
    "            allpreds = []\n",
    "            alltargets = []\n",
    "            alltargetnans = []\n",
    "            seqs =  [torch.FloatTensor(sequences[None,:,:]), torch.FloatTensor(sequences[None,::-1,::-1].copy())]\n",
    "\n",
    "            twotargets = [ targets_h1esc[None,:], targets_hff[None,:]]\n",
    "            twonormmats = [ normmats_h1esc[None,:], normmats_hff[None,:]]\n",
    "            for iii, seq in enumerate(seqs):\n",
    "                for ii, model in enumerate([h1esc_256m, hff_256m]):\n",
    "                    target = twotargets[ii]\n",
    "                    normmat = twonormmats[ii]\n",
    "                    encoding0 = model.net1(model.net0(seq.cuda().transpose(1,2)))[-1]\n",
    "                    encoding32, encoding64, encoding128, encoding256  = model.net(encoding0)\n",
    "                    encodings =  {32:encoding32, 64:encoding64, 128:encoding128, 256:encoding256}\n",
    "                    def eval_step(model, level, start, target,  normmat, coarse_pred=None):\n",
    "                        d = int(level/8)\n",
    "                        target_r = np.nanmean(np.nanmean(np.reshape(target[:,start:start+250* d,start:start+250*d],(target.shape[0],250,d,250,d)),axis=4),axis=2)\n",
    "                        target_nan =  np.mean(np.mean(np.isnan(np.reshape(target[:,start:start+250* d,start:start+250*d],(target.shape[0],250,d,250,d))),axis=4),axis=2)\n",
    "\n",
    "\n",
    "                        normmat_nan = np.isnan(normmat)\n",
    "                        if np.any(normmat_nan):\n",
    "                            normmat[normmat_nan] = np.nanmin(normmat[~normmat_nan])\n",
    "                        normmat_r = np.mean(np.mean(np.reshape(normmat[:,start:start+250*d,start:start+250*d],(normmat.shape[0],250,d,250,d)),axis=4),axis=2)\n",
    "\n",
    "                        if coarse_pred is not None:\n",
    "                            pred = model.denets[level].forward(encodings[level][:,:,int(start/d):int(start/d)+250], torch.log(torch.Tensor(normmat_r).cuda())[:,None,:,:], coarse_pred)\n",
    "                        else:\n",
    "                            pred = model.denets[level].forward(encodings[level][:,:,int(start/d):int(start/d)+250], torch.log(torch.Tensor(normmat_r).cuda())[:,None,:,:])\n",
    "                        eps = np.nanmin(normmat_r)\n",
    "                        target_cuda = torch.Tensor( np.log(((target_r+eps)/(normmat_r+ eps)))[:,0:,0:]).cuda()\n",
    "\n",
    "                        target_np = np.log((eps+target_r)/(eps+normmat_r))[:,0:,0:]\n",
    "\n",
    "                        return pred, target_np, target_nan\n",
    "                    \n",
    "                    if iii == 0:\n",
    "                        start = 0\n",
    "                        pred256, target256, targetnan256 = eval_step(model, 256, start, target, normmat)\n",
    "                        start = int(binstart)\n",
    "                        pred128, target128, targetnan128 = eval_step(model, 128, start, target, normmat, pred256[:,:,int(binstart/32):int(binstart/32)+125,int(binstart/32):int(binstart/32)+125])\n",
    "                        start = int(binstart)\n",
    "                        pred64, target64, targetnan64 = eval_step(model, 64, start, target, normmat, pred128[:,:,:125,:125])\n",
    "                        start = int(binstart)\n",
    "                        pred32, target32, targetnan32 = eval_step(model, 32, start, target, normmat, pred64[:,:,:125,:125])\n",
    "                    else:\n",
    "                        start = 0\n",
    "                        pred256, target256, targetnan256 = eval_step(model, 256, start, target[:,::-1,::-1], normmat[:,::-1,::-1])\n",
    "                        start = 8000 - int(binstart) - 4000\n",
    "                        pred128, target128, targetnan128 = eval_step(model, 128, start, target[:,::-1,::-1], normmat[:,::-1,::-1], pred256[:,:, 125-int(binstart/32): 250-int(binstart/32), 125-int(binstart/32): 250-int(binstart/32)])\n",
    "                        start = 8000 - int(binstart) - 2000\n",
    "                        pred64, target64, targetnan64 = eval_step(model, 64, start, target[:,::-1,::-1], normmat[:,::-1,::-1], pred128[:,:,125:,125:])\n",
    "                        start = 8000 - int(binstart) - 1000\n",
    "                        pred32, target32, targetnan32 = eval_step(model, 32, start, target[:,::-1,::-1], normmat[:,::-1,::-1], pred64[:,:,125:,125:])\n",
    "\n",
    "\n",
    "                    if binstart != 0:\n",
    "                        pred256 = None\n",
    "                        target256 = None\n",
    "                        targetnan256 = None\n",
    "                    else:\n",
    "                        if iii == 0:\n",
    "                            pred256[0,0,int(chrlen_round/1024000):,:]=np.nan\n",
    "                            target256[0,int(chrlen_round/1024000):,:]=np.nan\n",
    "                            targetnan256[0,int(chrlen_round/1024000):,:]=np.nan\n",
    "                            pred256[0,0,:,int(chrlen_round/1024000):]=np.nan\n",
    "                            target256[0,:,int(chrlen_round/1024000):]=np.nan\n",
    "                            targetnan256[0,:,int(chrlen_round/1024000):]=np.nan\n",
    "                        else:\n",
    "                            pred256[0,0,:250-int(chrlen_round/1024000),:]=np.nan\n",
    "                            target256[0,:250-int(chrlen_round/1024000),:]=np.nan\n",
    "                            targetnan256[0,:250-int(chrlen_round/1024000),:]=np.nan\n",
    "                            pred256[0,0,:,:250-int(chrlen_round/1024000)]=np.nan\n",
    "                            target256[0,:,:250-int(chrlen_round/1024000)]=np.nan\n",
    "                            targetnan256[0,:,:250-int(chrlen_round/1024000)]=np.nan\n",
    "                    if not binstart in binstarts[1]:\n",
    "                        pred64 = None\n",
    "                        target64 = None\n",
    "                        targetnan64 = None\n",
    "                        \n",
    "                    if not binstart in binstarts[2]:\n",
    "                        pred128 = None\n",
    "                        target128 = None\n",
    "                        targetnan128 = None\n",
    "                        \n",
    "\n",
    "                    allpreds.append([pred32, pred64, pred128, pred256])\n",
    "                    alltargets.append([target32, target64, target128, target256])\n",
    "                    alltargetnans.append([targetnan32, targetnan64, targetnan128, targetnan256])\n",
    "\n",
    "            mallpreds.append(allpreds)\n",
    "            malltargets.append(alltargets)\n",
    "            malltargetnans.append(alltargetnans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mallpreds, './figure_data/mallpreds.256m.pth')\n",
    "torch.save(malltargets, './figure_data/malltargets.256m.pth')\n",
    "torch.save(malltargetnans, './figure_data/malltargetnans.256m.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load precomputed \n",
    "import torch\n",
    "malltargets = torch.load('./figure_data/malltargets.256m.pth')\n",
    "malltargetnans = torch.load( './figure_data/malltargetnans.256m.pth')\n",
    "mallpreds = torch.load( './figure_data/mallpreds.256m.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in less_equal\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "p1s = defaultdict(list)\n",
    "p2s = defaultdict(list)\n",
    "t1s = defaultdict(list)\n",
    "t2s = defaultdict(list)\n",
    "\n",
    "levelsn = [32, 64, 128, 256]\n",
    "\n",
    "for i in range(len(mallpreds)):\n",
    "    for j in range(4):\n",
    "        if mallpreds[i][0][j] is not None:\n",
    "            \n",
    "            p1 = mallpreds[i][0][j].detach().cpu().numpy()[0,0,:,:][:,:].flatten()+mallpreds[i][2][j].detach().cpu().numpy()[0,0,::-1,::-1][:,:].flatten()\n",
    "            t1 = malltargets[i][0][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "            tn1 = malltargetnans[i][0][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "            p2 = mallpreds[i][1][j].detach().cpu().numpy()[0,0,:,:][:,:].flatten()+mallpreds[i][3][j].detach().cpu().numpy()[0,0,::-1,::-1][:,:].flatten()\n",
    "            t2 = malltargets[i][1][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "            tn2 = malltargetnans[i][1][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "\n",
    "            valid = np.isfinite(t1) * np.isfinite(t2)  * (tn1<=0.25) * (tn2<=0.25) \n",
    "\n",
    "\n",
    "            p1[~valid]=np.nan\n",
    "            t1[~valid]=np.nan\n",
    "\n",
    "            p1s[j].append(p1)\n",
    "            t1s[j].append(t1)\n",
    "\n",
    "\n",
    "            p2[~valid]=np.nan\n",
    "            t2[~valid]=np.nan\n",
    "            p2s[j].append(p2)\n",
    "            t2s[j].append(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1-ESC 32Mb 0.8215610872990484\n",
      "H1-ESC 64Mb 0.8455151960421428\n",
      "H1-ESC 128Mb 0.8401351029384021\n",
      "H1-ESC 256Mb 0.8457584284328606\n",
      "HFF 32Mb 0.7254492726664794\n",
      "HFF 64Mb 0.7255609148257045\n",
      "HFF 128Mb 0.7295147325253019\n",
      "HFF 256Mb 0.7484020607503034\n",
      "Diff 32Mb 0.4779782642676464\n",
      "Diff 64Mb 0.5124816993251585\n",
      "Diff 128Mb 0.5666834241982133\n",
      "Diff 256Mb 0.6254152099181652\n"
     ]
    }
   ],
   "source": [
    "#Intrachromosal performance\n",
    "for i, level in enumerate(['32Mb','64Mb','128Mb','256Mb']):\n",
    "    valid = np.isfinite(t1s[i])  \n",
    "    print('H1-ESC', level, pearsonr(np.array(p1s[i])[valid], np.array(t1s[i])[valid])[0])\n",
    "    \n",
    "for i, level in enumerate(['32Mb','64Mb','128Mb','256Mb']):\n",
    "    valid = np.isfinite(t2s[i])  \n",
    "    print('HFF', level, pearsonr(np.array(p2s[i])[valid], np.array(t2s[i])[valid])[0])\n",
    "\n",
    "for i, level in enumerate(['32Mb','64Mb','128Mb','256Mb']):\n",
    "    valid = np.isfinite(t2s[i]) \n",
    "    print('Diff', level, pearsonr(np.array(p2s[i])[valid]-np.array(p1s[i])[valid], np.array(t2s[i])[valid]-np.array(t1s[i])[valid])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import pandas as pd\n",
    "import plotnine\n",
    "plotnine.options.figure_size = (8, 6)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "levels = ['32Mb','64Mb','128Mb','256Mb'] \n",
    "plotdata = []\n",
    "for i in range(0,4):\n",
    "    valid = np.isfinite(t1s[i]) #* np.isfinite(t2s[i])\n",
    "    subsetind = np.random.permutation(np.sum(valid))[:100000]\n",
    "    plotdata.append(pd.DataFrame({'x':np.array(p1s[i])[valid][subsetind], 'y':np.array(t1s[i])[valid][subsetind], \\\n",
    "                                  'level': levels[i], 'cell': 'H1-ESC'}))\n",
    "    plotdata.append(pd.DataFrame({'x':np.array(p2s[i])[valid][subsetind], 'y':np.array(t2s[i])[valid][subsetind], \\\n",
    "                                  'level': levels[i], 'cell': 'HFF'}))\n",
    "    \n",
    "plotdata = pd.concat(plotdata, axis=0)\n",
    "plotdata['level'] = pd.Categorical(plotdata['level'], levels)\n",
    "\n",
    "plotdata.to_csv('./figure_data/predeval.256m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19298 0.9656880226581053\n",
      "12120 0.9521985547191025\n",
      "2226 0.9621304642822526\n",
      "264 0.9960973370064279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
      "  if __name__ == '__main__':\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
      "  if __name__ == '__main__':\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import pandas as pd\n",
    "levels = ['32Mb','64Mb','128Mb','256Mb']\n",
    "plotdata = []\n",
    "for i in range(0, 4):\n",
    "    valid = np.isfinite(t2s[i])  \n",
    "    thresh = np.quantile(np.abs(np.array(t2s[i])-np.array(t1s[i]))[valid], 0.99)\n",
    "    valid = valid * (np.abs(np.array(t2s[i])-np.array(t1s[i]))> thresh)\n",
    "    \n",
    "    print(np.sum(valid),roc_auc_score(\n",
    "                 (np.array(t2s[i])[valid]-np.array(t1s[i])[valid])>0,\n",
    "                 np.array(p2s[i])[valid] - np.array(p1s[i])[valid]))\n",
    "    fpr, tpr, _ = roc_curve(\n",
    "                 (np.array(t2s[i])[valid]-np.array(t1s[i])[valid])>0,\n",
    "                 np.array(p2s[i])[valid] - np.array(p1s[i])[valid])\n",
    "    plotdata.append(pd.DataFrame({'FPR':fpr,'TPR':tpr,'level':levels[i]}))\n",
    "\n",
    "plotdata=pd.concat(plotdata, axis=0)\n",
    "plotdata.to_csv('./figure_data/predeval.roc.256m.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selene_utils2 import * \n",
    "sampler_h1esc = RandomPositionsSamplerHiC(\n",
    "\n",
    "                 reference_sequence = MemmapGenome(ORCA_PATH+'/resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa', memmapfile=ORCA_PATH+'/resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa.mmap'),\n",
    "                 target= Genomic2DFeatures([ORCA_PATH+'/resources/4DNFI9GMP2J8.rebinned.mcool::/resolutions/32000'],\n",
    "                           ['r8000'],\n",
    "                          (8000,8000),\n",
    "                          cg=True),\n",
    "                 features = ['r4000'],\n",
    "                 test_holdout=['chr9', 'chr10'],\n",
    "                 validation_holdout= ['chr8'],\n",
    "                 sequence_length= 256000000,\n",
    "                 position_resolution=32000,\n",
    "                 random_shift=0,\n",
    "                 random_strand=True,\n",
    "                 cross_chromosome=True,\n",
    "                 permute_segments=True,\n",
    "                 length_schedule=[1, [64000000, 128000000]],\n",
    "                 background_cis_file=ORCA_PATH+'/resources/4DNFI9GMP2J8.rebinned.mcool.expected.res32000.mono.npy',\n",
    "                 background_trans_file=ORCA_PATH+'/resources/4DNFI9GMP2J8.rebinned.mcool.expected.res32000.trans.npy'\n",
    " )\n",
    "    \n",
    "sampler_hff = RandomPositionsSamplerHiC(\n",
    "\n",
    "                 reference_sequence = MemmapGenome(ORCA_PATH+'/resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa', memmapfile=ORCA_PATH+'/resources/Homo_sapiens.GRCh38.dna.primary_assembly.fa.mmap'),\n",
    "                 target= Genomic2DFeatures([ORCA_PATH+'/resources/4DNFI643OYP9.rebinned.mcool::/resolutions/32000'],\n",
    "                           ['r8000'],\n",
    "                          (8000,8000),\n",
    "                          cg=True),\n",
    "                 features = ['r4000'],\n",
    "                 test_holdout=['chr9', 'chr10'],\n",
    "                 validation_holdout= ['chr8'],\n",
    "                 sequence_length= 256000000,\n",
    "                 position_resolution=32000,\n",
    "                 random_shift=0,\n",
    "                 random_strand=True,\n",
    "                 cross_chromosome=True,\n",
    "                 permute_segments=True,\n",
    "                 length_schedule=[1, [64000000, 128000000]],\n",
    "                 background_cis_file=ORCA_PATH+'/resources/4DNFI643OYP9.rebinned.mcool.expected.res32000.mono.npy',\n",
    "                 background_trans_file=ORCA_PATH+'/resources/4DNFI643OYP9.rebinned.mcool.expected.res32000.trans.npy'\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<PYTHONPATH>/lib/python3.7/site-packages/cooltools/lib/numutils.py:1317: RuntimeWarning: invalid value encountered in true_divide\n",
      "  val_cur = ar_cur / armask_cur\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/cooltools/lib/numutils.py:1317: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  val_cur = ar_cur / armask_cur\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: Mean of empty slice\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "#32-256Mb model evaluation, interchromosomal interactions\n",
    "\n",
    "import torch\n",
    "np.random.seed(213)\n",
    "with torch.no_grad():\n",
    "    \n",
    "    callpreds = []\n",
    "    calltargets = []\n",
    "    calltargetnans = []\n",
    "    callnormmats = []\n",
    "    for i in range(100):\n",
    "        sampler_h1esc.mode='test'\n",
    "        sampled = sampler_h1esc.sample(coordinate_only=True)\n",
    "        sequences, targets_h1esc, normmats_h1esc = sampler_h1esc._retrieve_multi(*sampled[0])\n",
    "        _, targets_hff, normmats_hff = sampler_hff._retrieve_multi(*sampled[0])\n",
    "\n",
    "        sequences = np.vstack(sequences)\n",
    "        targets_h1esc = np.vstack([np.hstack(l) for l in targets_h1esc])\n",
    "        normmats_h1esc = np.vstack([np.hstack(l) for l in normmats_h1esc])\n",
    "        targets_hff = np.vstack([np.hstack(l) for l in targets_hff])\n",
    "        normmats_hff = np.vstack([np.hstack(l) for l in normmats_hff])\n",
    "        \n",
    "\n",
    "        allpreds = []\n",
    "        alltargets = []\n",
    "        alltargetnans = []\n",
    "        allnormmats = []\n",
    "        seqs =  [torch.FloatTensor(sequences[None,:,:]), torch.FloatTensor(sequences[None,::-1,::-1].copy())]\n",
    "\n",
    "        twotargets = [ targets_h1esc[None,:], targets_hff[None,:]]\n",
    "        twonormmats = [ normmats_h1esc[None,:], normmats_hff[None,:]]\n",
    "        for iii, seq in enumerate(seqs):\n",
    "            for ii, model in enumerate([h1esc_256m, hff_256m]):\n",
    "                target = twotargets[ii]\n",
    "                normmat = twonormmats[ii]\n",
    "                encoding0 = model.net1(model.net0(seq.cuda().transpose(1,2)))[-1]\n",
    "                encoding32, encoding64, encoding128, encoding256  = model.net(encoding0)\n",
    "                encodings =  {32:encoding32, 64:encoding64, 128:encoding128, 256:encoding256}\n",
    "                def eval_step(model, level, start, target,  normmat, coarse_pred=None):\n",
    "                    d = int(level/8)\n",
    "                    target_r = np.nanmean(np.nanmean(np.reshape(target[:,start:start+250* d,start:start+250*d],(target.shape[0],250,d,250,d)),axis=4),axis=2)\n",
    "                    target_nan =  np.mean(np.mean(np.isnan(np.reshape(target[:,start:start+250* d,start:start+250*d],(target.shape[0],250,d,250,d))),axis=4),axis=2)\n",
    "\n",
    "\n",
    "                    normmat_nan = np.isnan(normmat)\n",
    "                    if np.any(normmat_nan):\n",
    "                        normmat[normmat_nan] = np.nanmin(normmat[~normmat_nan])\n",
    "                    normmat_r = np.mean(np.mean(np.reshape(normmat[:,start:start+250*d,start:start+250*d],(normmat.shape[0],250,d,250,d)),axis=4),axis=2)\n",
    "\n",
    "                    if coarse_pred is not None:\n",
    "                        pred = model.denets[level].forward(encodings[level][:,:,int(start/d):int(start/d)+250], torch.log(torch.Tensor(normmat_r).cuda())[:,None,:,:], coarse_pred)\n",
    "                    else:\n",
    "                        pred = model.denets[level].forward(encodings[level][:,:,int(start/d):int(start/d)+250], torch.log(torch.Tensor(normmat_r).cuda())[:,None,:,:])\n",
    "                    eps = np.nanmin(normmat_r)\n",
    "                    target_cuda = torch.Tensor( np.log(((target_r+eps)/(normmat_r+ eps)))[:,0:,0:]).cuda()\n",
    "\n",
    "                    target_np = np.log((eps+target_r)/(eps+normmat_r))[:,0:,0:]\n",
    "\n",
    "                    return pred, target_np, target_nan, normmat_r\n",
    "\n",
    "                if iii == 0:\n",
    "                    start = 0\n",
    "                    pred256, target256, targetnan256, normmat256 = eval_step(model, 256, start, target, normmat)\n",
    "                    start = 63 * 32\n",
    "                    pred128, target128, targetnan128, normmat128 = eval_step(model, 128, start, target, normmat, pred256[:,:,63:63+125,63:63+125])\n",
    "                    start += 62 * 16\n",
    "                    pred64, target64, targetnan64, normmat64 = eval_step(model, 64, start, target, normmat, pred128[:,:,62:62+125,62:62+125])\n",
    "                    start += 62 * 8\n",
    "                    pred32, target32, targetnan32, normmat32 = eval_step(model, 32, start, target, normmat, pred64[:,:,62:62+125,62:62+125])\n",
    "                else:\n",
    "                    start = 0\n",
    "                    pred256, target256, targetnan256, normmat256 = eval_step(model, 256, start, target[:,::-1,::-1], normmat[:,::-1,::-1])\n",
    "                    start = 62 * 32\n",
    "                    pred128, target128, targetnan128, normmat128 = eval_step(model, 128, start, target[:,::-1,::-1], normmat[:,::-1,::-1], pred256[:,:,62:62+125,62:62+125])\n",
    "                    start += 63 * 16\n",
    "                    pred64, target64, targetnan64, normmat64 = eval_step(model, 64, start, target[:,::-1,::-1], normmat[:,::-1,::-1], pred128[:,:,63:63+125,63:63+125])\n",
    "                    start += 63 * 8\n",
    "                    pred32, target32, targetnan32, normmat32 = eval_step(model, 32, start, target[:,::-1,::-1], normmat[:,::-1,::-1], pred64[:,:,63:63+125,63:63+125])\n",
    "\n",
    "                allpreds.append([pred32, pred64, pred128, pred256])\n",
    "                alltargets.append([target32, target64, target128, target256])\n",
    "                alltargetnans.append([targetnan32, targetnan64, targetnan128, targetnan256])\n",
    "                allnormmats.append([normmat32, normmat64, normmat128, normmat256])\n",
    "\n",
    "        callpreds.append(allpreds)\n",
    "        calltargets.append(alltargets)\n",
    "        calltargetnans.append(alltargetnans)\n",
    "        callnormmats.append(allnormmats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(calltargets, './figure_data/calltargets.256m.pth')\n",
    "torch.save(calltargetnans, './figure_data/calltargetnans.256m.pth')\n",
    "torch.save(callnormmats, './figure_data/callnormmats.256m.pth')\n",
    "torch.save(callpreds, './figure_data/callpreds.256m.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "calltargets = torch.load('./figure_data/calltargets.256m.pth')\n",
    "calltargetnans = torch.load('./figure_data/calltargetnans.256m.pth')\n",
    "callnormmats = torch.load('./figure_data/callnormmats.256m.pth')\n",
    "callpreds = torch.load('./figure_data/callpreds.256m.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: Mean of empty slice\n",
      "  \"\"\"\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: Mean of empty slice\n",
      "  \n",
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: Mean of empty slice\n",
      "  import sys\n",
      "<PYTHONPATH>/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: Mean of empty slice\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "normmats = h1esc_256m.background_cis[np.abs(np.arange(8000)[None,:]-np.arange(8000)[:,None])]\n",
    "normmats = [np.nanmean(np.nanmean(np.reshape(normmats,(2000,4,2000,4)),axis=3),axis=1)[:250,:250],\n",
    "            np.nanmean(np.nanmean(np.reshape(normmats,(1000,8,1000,8)),axis=3),axis=1)[:250,:250],\n",
    "            np.nanmean(np.nanmean(np.reshape(normmats,(500,16,500,16)),axis=3),axis=1)[:250,:250],\n",
    "            np.nanmean(np.nanmean(np.reshape(normmats,(250,32,250,32)),axis=3),axis=1)[:250,:250]]\n",
    "\n",
    "\n",
    "p1s = defaultdict(list)\n",
    "p2s = defaultdict(list)\n",
    "t1s = defaultdict(list)\n",
    "t2s = defaultdict(list)\n",
    "\n",
    "levelsn = [32, 64, 128, 256]\n",
    "\n",
    "for i in range(len(callpreds)):\n",
    "    for j in range(4):\n",
    "        if callpreds[i][0][j] is not None:\n",
    "            \n",
    "            p1 = callpreds[i][0][j].detach().cpu().numpy()[0,0,:,:][:,:].flatten()+callpreds[i][2][j].detach().cpu().numpy()[0,0,::-1,::-1][:,:].flatten()\n",
    "            t1 = calltargets[i][0][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "            tn1 = calltargetnans[i][0][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "            p2 = callpreds[i][1][j].detach().cpu().numpy()[0,0,:,:][:,:].flatten()+callpreds[i][3][j].detach().cpu().numpy()[0,0,::-1,::-1][:,:].flatten()\n",
    "            t2 = calltargets[i][1][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "            tn2 = calltargetnans[i][1][j][0,:].reshape((250,250))[:,:].flatten()\n",
    "\n",
    "            \n",
    "            #selecting interchromosomal interactions \n",
    "            valid = np.isfinite(t1) * np.isfinite(t2)  * (tn1<=0.25)  * (np.isclose(callnormmats[i][0][j][0], 3.4847237202484393e-06).flatten())\n",
    "\n",
    "\n",
    "            p1[~valid]=np.nan\n",
    "            t1[~valid]=np.nan\n",
    "\n",
    "            p1s[j].append(p1)\n",
    "            t1s[j].append(t1)\n",
    "\n",
    "            p2[~valid]=np.nan\n",
    "            t2[~valid]=np.nan\n",
    "            p2s[j].append(p2)\n",
    "            t2s[j].append(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1ESC 32Mb 0.3869214518155263\n",
      "H1ESC 64Mb 0.5209612660142798\n",
      "H1ESC 128Mb 0.6377317985850213\n",
      "H1ESC 256Mb 0.7373308957499379\n",
      "HFF 32Mb 0.357238538502456\n",
      "HFF 64Mb 0.47171294377137646\n",
      "HFF 128Mb 0.6071246770073321\n",
      "HFF 256Mb 0.7108015679685028\n",
      "Diff 32Mb 0.18144108039893062\n",
      "Diff 64Mb 0.21590998331714942\n",
      "Diff 128Mb 0.27160963844701286\n",
      "Diff 256Mb 0.3723438985789733\n"
     ]
    }
   ],
   "source": [
    "#Interchromosomal performance \n",
    "for i, level in enumerate(['32Mb','64Mb','128Mb','256Mb']):\n",
    "    valid = np.isfinite(t1s[i])  \n",
    "    print('H1ESC', level, pearsonr(np.array(p1s[i])[valid], np.array(t1s[i])[valid])[0])\n",
    "    \n",
    "for i, level in enumerate(['32Mb','64Mb','128Mb','256Mb']):\n",
    "    valid = np.isfinite(t2s[i])  \n",
    "    print('HFF', level, pearsonr(np.array(p2s[i])[valid], np.array(t2s[i])[valid])[0])\n",
    "\n",
    "for i, level in enumerate(['32Mb','64Mb','128Mb','256Mb']):\n",
    "    valid = np.isfinite(t2s[i]) \n",
    "    print('Diff', level, pearsonr(np.array(p2s[i])[valid]-np.array(p1s[i])[valid], np.array(t2s[i])[valid]-np.array(t1s[i])[valid])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import pandas as pd\n",
    "import plotnine\n",
    "plotnine.options.figure_size = (8, 6)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "levels = ['32Mb','64Mb','128Mb','256Mb'] \n",
    "plotdata = []\n",
    "for i in range(4):\n",
    "    valid = np.isfinite(t1s[i]) #* np.isfinite(t2s[i])\n",
    "    subsetind = np.random.permutation(np.sum(valid))[:100000]\n",
    "    plotdata.append(pd.DataFrame({'x':np.array(p1s[i])[valid][subsetind], 'y':np.array(t1s[i])[valid][subsetind], \\\n",
    "                                  'level': levels[i], 'cell': 'H1-ESC'}))\n",
    "    plotdata.append(pd.DataFrame({'x':np.array(p2s[i])[valid][subsetind], 'y':np.array(t2s[i])[valid][subsetind], \\\n",
    "                                  'level': levels[i], 'cell': 'HFF'}))\n",
    "    \n",
    "plotdata = pd.concat(plotdata, axis=0)\n",
    "plotdata['level'] = pd.Categorical(plotdata['level'], levels)\n",
    "plotdata.to_csv('./figure_data/predeval.256m.crosschrom.inter.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
